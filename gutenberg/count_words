#!/usr/bin/python3

# This file is part of Project Babel.
# Copyright 2021 Graham Shaw
# Redistribution and modification are permitted within the terms of the
# BSD-3-Clause licence as defined by v3.4 of the SPDX Licence List.

import sys
import argparse
import re
import json

# Note that:
# - Words containing capital letters are rejected, in order to exclude proper
#   nounts. This has the side effect of discarding the first word of each
#   sentence.
# - Words are split on apostrophes. This results in large numbers of counts
#   for letters and letter pairs such as 's' and 't', 'n' and 'll'.
# This behaviour would make the results unsuitable for some purposes, but it
# is not expected to detract from the intended function of determing whether
# a piece of text is written in a given language.

parser = argparse.ArgumentParser(
    description = 'Count word frequencies.')
parser.add_argument('-l', '--lang', action='append',
    help='BCP 47 language tag to accept')
parser.add_argument('-n', '--number', type=int,
    help='maximum number of words to report')
parser.add_argument('texts', nargs='?', default=None,
    help='a JSON file containing the texts to processed')
args = parser.parse_args()

def handle_paragraph(para, wordcounts):
    words = re.split('[^A-Za-z0-9]+', para)
    for word in words:
        if re.match('^[a-z]+$', word):
            if word in wordcounts:
                wordcounts[word] += 1
            else:
                wordcounts[word] = 1

wordcounts = {}
texts = sys.stdin
if args.texts:
    texts = open(args.texts, 'r')
for line in texts:
    text = json.loads(line)
    for para in text['paragraphs']:
        handle_paragraph(para, wordcounts)

wordlist = [{'word': word, 'count': count} for word, count in wordcounts.items()]
wordlist.sort(key=lambda entry: -entry['count'])
wordlist = wordlist[:args.number]
for entry in wordlist:
    print(json.dumps(entry))
